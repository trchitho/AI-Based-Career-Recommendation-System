"""
Story Generator Service using Gemini AI
Generates interactive story scenarios for assessment questions
"""
import os
import logging
import json
from typing import List, Dict, Any
import google.generativeai as genai

logger = logging.getLogger(__name__)

class StoryGeneratorService:
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        self.model_name = os.getenv("GEMINI_MODEL", "gemini-pro")
        
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY not found in environment variables")
        
        genai.configure(api_key=self.api_key)
        self.model = None
        self._initialize_model()
    
    def _initialize_model(self):
        """Initialize Gemini model with fallback - same as chatbot"""
        models_to_try = [
            "models/gemma-3-4b-it",  # Free model, works well
            "models/gemma-3-1b-it",
            "models/gemini-2.0-flash-lite",
            "models/gemini-flash-lite-latest",
            "models/gemini-2.5-flash-lite",
            "models/gemini-flash-latest",
            "gemini-1.5-flash",
            "gemini-pro"
        ]
        
        for model_name in models_to_try:
            try:
                logger.info(f"Trying to initialize model: {model_name}")
                model = genai.GenerativeModel(model_name)
                
                # Test the model with a simple request
                test_response = model.generate_content(
                    "Test",
                    generation_config=genai.types.GenerationConfig(
                        max_output_tokens=10,
                        temperature=0.1,
                    )
                )
                
                logger.info(f"Successfully initialized Gemini model: {model_name}")
                self.model = model
                return
            except Exception as e:
                logger.warning(f"Failed to initialize model {model_name}: {e}")
                continue
        
        raise ValueError("No working Gemini model found")
    
    def generate_group_story(self, questions: List[Dict[str, Any]], group_index: int) -> Dict[str, Any]:
        """
        Generate a connected story for a group of 5 questions
        
        Args:
            questions: List of question dicts with id, question_text, dimension
            group_index: Index of the question group
            
        Returns:
            Dict with groupScenario and questionScenarios
        """
        try:
            prompt = self._build_group_prompt(questions, group_index)
            response = self.model.generate_content(prompt)
            
            # Parse JSON response
            response_text = response.text.strip()
            
            # Remove markdown code blocks if present
            if response_text.startswith('```json'):
                response_text = response_text.replace('```json\n', '').replace('```', '')
            elif response_text.startswith('```'):
                response_text = response_text.replace('```\n', '').replace('```', '')
            
            result = json.loads(response_text)
            
            return {
                'groupScenario': {
                    'emoji': result.get('groupScenario', {}).get('emoji', 'üìñ'),
                    'title': result.get('groupScenario', {}).get('title', 'T√¨nh Hu·ªëng'),
                    'introduction': result.get('groupScenario', {}).get('introduction', 'H√£y tr·∫£i nghi·ªám c√°c t√¨nh hu·ªëng sau...')
                },
                'questionScenarios': [
                    {
                        'emoji': q.get('emoji', 'üí≠'),
                        'title': q.get('title', f'C√¢u h·ªèi {idx + 1}'),
                        'context': q.get('context', 'Trong t√¨nh hu·ªëng n√†y...'),
                        'situation': q.get('situation', questions[idx].get('question_text', ''))
                    }
                    for idx, q in enumerate(result.get('questions', []))
                ]
            }
            
        except Exception as e:
            logger.error(f"Error generating group story: {e}")
            return self._get_fallback_group_story(questions, group_index)
    
    def _build_group_prompt(self, questions: List[Dict[str, Any]], group_index: int) -> str:
        """Build prompt for Gemini AI"""
        questions_list = '\n'.join([
            f"{idx + 1}. \"{q.get('question_text', '')}\" ({q.get('dimension', 'general')})"
            for idx, q in enumerate(questions)
        ])
        
        return f"""
B·∫°n l√† m·ªôt chuy√™n gia t·∫°o c√¢u chuy·ªán t∆∞∆°ng t√°c cho b√†i ƒë√°nh gi√° ngh·ªÅ nghi·ªáp.

NHI·ªÜM V·ª§: T·∫°o m·ªôt c√¢u chuy·ªán li√™n k·∫øt cho nh√≥m 5 c√¢u h·ªèi sau, bi·∫øn ch√∫ng th√†nh m·ªôt t√¨nh hu·ªëng th·ª±c t·∫ø, sinh ƒë·ªông.

NH√ìM C√ÇU H·ªéI {group_index + 1}:
{questions_list}

Y√äU C·∫¶U:
1. T·∫°o m·ªôt b·ªëi c·∫£nh chung (scenario) cho c·∫£ nh√≥m 5 c√¢u h·ªèi
2. M·ªói c√¢u h·ªèi l√† m·ªôt ph·∫ßn c·ªßa c√¢u chuy·ªán ƒë√≥
3. C√¢u chuy·ªán ph·∫£i m·∫°ch l·∫°c, li√™n k·∫øt v·ªõi nhau
4. S·ª≠ d·ª•ng ng√¥n ng·ªØ Vi·ªát Nam t·ª± nhi√™n, th√¢n thi·ªán
5. T·∫°o c·∫£m gi√°c nh∆∞ ng∆∞·ªùi d√πng ƒëang tr·∫£i nghi·ªám m·ªôt t√¨nh hu·ªëng th·ª±c t·∫ø

TR·∫¢ V·ªÄ JSON FORMAT (ch·ªâ JSON, kh√¥ng c√≥ text kh√°c):
{{
  "groupScenario": {{
    "emoji": "emoji ph√π h·ª£p v·ªõi nh√≥m (v√≠ d·ª•: üè¢, üé®, üî¨, ü§ù)",
    "title": "Ti√™u ƒë·ªÅ cho nh√≥m t√¨nh hu·ªëng (3-6 t·ª´, ti·∫øng Vi·ªát)",
    "introduction": "Gi·ªõi thi·ªáu b·ªëi c·∫£nh chung cho 5 c√¢u h·ªèi (2-3 c√¢u, ti·∫øng Vi·ªát)"
  }},
  "questions": [
    {{
      "emoji": "emoji cho c√¢u h·ªèi 1",
      "title": "Ti√™u ƒë·ªÅ ng·∫Øn (3-5 t·ª´)",
      "context": "K·ªãch b·∫£n/b·ªëi c·∫£nh chi ti·∫øt c·ªßa t√¨nh hu·ªëng (2-3 c√¢u, m√¥ t·∫£ sinh ƒë·ªông)",
      "situation": "C√¢u h·ªèi ng·∫Øn g·ªçn d·ª±a tr√™n c√¢u h·ªèi g·ªëc (1 c√¢u)"
    }}
  ]
}}

V√ç D·ª§:
Nh√≥m c√¢u h·ªèi v·ªÅ c√¥ng vi·ªác vƒÉn ph√≤ng:
{{
  "groupScenario": {{
    "emoji": "üè¢",
    "title": "M·ªôt Ng√†y T·∫°i C√¥ng Ty",
    "introduction": "B·∫°n l√† m·ªôt nh√¢n vi√™n m·ªõi t·∫°i m·ªôt c√¥ng ty c√¥ng ngh·ªá. H√¥m nay l√† ng√†y ƒë·∫ßu ti√™n v√† b·∫°n s·∫Ω tr·∫£i qua nhi·ªÅu t√¨nh hu·ªëng kh√°c nhau."
  }},
  "questions": [
    {{
      "emoji": "üíª",
      "title": "S·∫Øp X·∫øp C√¥ng Vi·ªác",
      "context": "S√°ng s·ªõm, b·∫°n nh·∫≠n ƒë∆∞·ª£c m·ªôt danh s√°ch d√†i c√°c nhi·ªám v·ª• c·∫ßn ho√†n th√†nh trong tu·∫ßn n√†y. C√≥ nh·ªØng c√¥ng vi·ªác kh·∫©n c·∫•p, c√≥ nh·ªØng vi·ªác quan tr·ªçng nh∆∞ng kh√¥ng g·∫•p, v√† c·∫£ nh·ªØng vi·ªác nh·ªè l·∫ª. B·∫°n c·∫ßn quy·∫øt ƒë·ªãnh c√°ch t·ªï ch·ª©c c√¥ng vi·ªác.",
      "situation": "B·∫°n th√≠ch l·∫≠p k·∫ø ho·∫°ch chi ti·∫øt v√† s·∫Øp x·∫øp c√¥ng vi·ªác theo th·ª© t·ª± ∆∞u ti√™n."
    }}
  ]
}}

B·∫ÆT ƒê·∫¶U T·∫†O CHO NH√ìM C√ÇU H·ªéI TR√äN:
"""
    
    def _get_fallback_group_story(self, questions: List[Dict[str, Any]], group_index: int) -> Dict[str, Any]:
        """Fallback scenarios when AI fails"""
        dimensions = [q.get('dimension', '').lower() for q in questions if q.get('dimension')]
        
        group_themes = {
            'realistic': {
                'emoji': 'üîß',
                'title': 'Th·ª≠ Th√°ch K·ªπ Thu·∫≠t',
                'introduction': 'B·∫°n ƒëang l√†m vi·ªác trong m·ªôt x∆∞·ªüng v·ªõi nhi·ªÅu c√¥ng c·ª• v√† thi·∫øt b·ªã. H√£y tr·∫£i nghi·ªám c√°c t√¨nh hu·ªëng sau.'
            },
            'investigative': {
                'emoji': 'üî¨',
                'title': 'Ph√≤ng Nghi√™n C·ª©u',
                'introduction': 'B·∫°n l√† m·ªôt nh√† nghi√™n c·ª©u trong ph√≤ng th√≠ nghi·ªám. H√¥m nay b·∫°n s·∫Ω ƒë·ªëi m·∫∑t v·ªõi nhi·ªÅu th·ª≠ th√°ch khoa h·ªçc.'
            },
            'artistic': {
                'emoji': 'üé®',
                'title': 'Studio S√°ng T·∫°o',
                'introduction': 'B·∫°n b∆∞·ªõc v√†o m·ªôt studio ngh·ªá thu·∫≠t ƒë·∫ßy c·∫£m h·ª©ng. H√£y kh√°m ph√° kh·∫£ nƒÉng s√°ng t·∫°o c·ªßa b·∫°n.'
            },
            'social': {
                'emoji': 'ü§ù',
                'title': 'Trung T√¢m C·ªông ƒê·ªìng',
                'introduction': 'B·∫°n ƒëang l√†m vi·ªác t·∫°i trung t√¢m c·ªông ƒë·ªìng. Nhi·ªÅu ng∆∞·ªùi c·∫ßn s·ª± gi√∫p ƒë·ª° v√† h·ªó tr·ª£ t·ª´ b·∫°n.'
            },
            'enterprising': {
                'emoji': 'üíº',
                'title': 'VƒÉn Ph√≤ng Kinh Doanh',
                'introduction': 'B·∫°n l√† m·ªôt nh√¢n vi√™n trong c√¥ng ty. H√¥m nay c√≥ nhi·ªÅu quy·∫øt ƒë·ªãnh quan tr·ªçng c·∫ßn ƒë∆∞·ª£c ƒë∆∞a ra.'
            },
            'conventional': {
                'emoji': 'üìä',
                'title': 'Ph√≤ng Ph√¢n T√≠ch D·ªØ Li·ªáu',
                'introduction': 'B·∫°n l√†m vi·ªác v·ªõi s·ªë li·ªáu v√† bi·ªÉu ƒë·ªì. H√£y s·ª≠ d·ª•ng k·ªπ nƒÉng t·ªï ch·ª©c v√† ph√¢n t√≠ch c·ªßa b·∫°n.'
            }
        }
        
        # Find matching theme
        group_scenario = group_themes['conventional']  # default
        for dim in dimensions:
            if dim in group_themes:
                group_scenario = group_themes[dim]
                break
        
        # Generate scenarios for each question
        question_scenarios = []
        for idx, q in enumerate(questions):
            question_scenarios.append({
                'emoji': 'üí≠',
                'title': f'T√¨nh Hu·ªëng {idx + 1}',
                'context': 'H√£y suy nghƒ© v·ªÅ t√¨nh hu·ªëng n√†y...',
                'situation': q.get('question_text', '')
            })
        
        return {
            'groupScenario': group_scenario,
            'questionScenarios': question_scenarios
        }
