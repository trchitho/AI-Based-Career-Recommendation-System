# app/modules/recommendation/service.py
from __future__ import annotations

import os
import uuid
from typing import Any, Dict, List, Optional

import httpx
from sqlalchemy import text
from sqlalchemy.orm import Session

from app.core.logging import logger

AI_CORE_BASE_URL = os.getenv("AI_CORE_BASE_URL", "http://localhost:9000").rstrip("/")


class RecService:
    """
    BFF Recommendation service ‚Äì assessment-based.

    Lu·ªìng:
    - FE truy·ªÅn assessment_id.
    - BFF g·ªçi AI-core /recs/top_careers v·ªõi assessment_id.
    - AI-core d√πng snapshot traits + embedding t·∫°i th·ªùi ƒëi·ªÉm l√†m b√†i ƒë·ªÉ recommend.
    - BFF:
        + Join core.careers ƒë·ªÉ l·∫•y slug, title, desc, tags RIASEC.
        + L·ªçc theo RIASEC c·ªßa ch√≠nh assessment ƒë√≥.
        + Chu·∫©n ho√° display_match.
        + Log analytics v√†o analytics.career_events.
    """

    def get_onet_code_by_slug(self, db: Session, career_id_or_slug: str) -> Optional[str]:
        """
        Map slug <-> onet_code.
        Tr·∫£ v·ªÅ onet_code n·∫øu t√¨m ƒë∆∞·ª£c, ng∆∞·ª£c l·∫°i None.
        """
        row = db.execute(
            text(
                """
                SELECT onet_code
                FROM core.careers
                WHERE slug = :cid OR onet_code = :cid
                LIMIT 1
                """
            ),
            {"cid": career_id_or_slug},
        ).fetchone()

        if not row:
            return None
        return row[0]

    # ====================================================================== #
    # 1. Attach metadata & RIASEC tags
    # ====================================================================== #

    def _attach_career_meta(
        self,
        db: Session,
        items: List[Dict[str, Any]],
    ) -> List[Dict[str, Any]]:
        """
        Nh·∫≠n list item t·ª´ AI-core:
        [
          {"career_id": "11-1011.00", "final_score": 0.92},
          ...
        ]

        - Map career_id (O*NET code) -> row trong core.careers + nh√£n RIASEC.
        - Tr·∫£ v·ªÅ list DTO th√¥ cho FE.
        """
        dto_list: List[Dict[str, Any]] = []

        for raw in items:
            onet_code = (
                raw.get("job_onet")
                or raw.get("career_id")
                or raw.get("job_id")
            )
            if not onet_code:
                continue

            meta = self._load_career_meta(db, onet_code)
            if not meta:
                # ch∆∞a enrich metadata th√¨ b·ªè qua ngh·ªÅ n√†y
                continue

            slug = meta.get("slug") or onet_code
            riasec_codes = meta.get("riasec_codes") or []

            score = (
                raw.get("match_score")
                or raw.get("score")
                or raw.get("final_score")
                or 0.0
            )

            dto = {
                "career_id": slug,         # FE d√πng slug l√†m id
                "slug": slug,
                "job_onet": onet_code,     # gi·ªØ O*NET ƒë·ªÉ log / debug
                "title_vi": meta.get("title_vi"),
                "title_en": meta.get("title_en"),
                "description": (
                    meta.get("short_desc_en")
                    or meta.get("short_desc_vn")
                    or meta.get("description")
                    or ""
                ),
                "tags": riasec_codes,      # ["R", "RI", ...]
                "job_zone": meta.get("job_zone"),
                "match_score": float(score),
                "display_match": raw.get("display_match"),
                "position": raw.get("position", 0),
            }
            dto_list.append(dto)

        dto_list.sort(key=lambda x: x["match_score"], reverse=True)
        return dto_list

    # ====================================================================== #
    # 2. RIASEC filter (d·ª±a tr√™n Top 2 RIASEC dimensions - L1 & L2 ONLY)
    # ====================================================================== #

    def _filter_by_riasec_top2(
        self,
        jobs: List[Dict[str, Any]],
        riasec_scores: List[float],
        top_k: int,
    ) -> List[Dict[str, Any]]:
        """
        Filter ngh·ªÅ theo RIASEC v·ªõi logic: CH·ªà d√πng L1 (top 1) v√† L2 (top 2).
        KH√îNG d√πng top 3 RIASEC dimension.
        
        Args:
            jobs: List ngh·ªÅ t·ª´ AI-core (ƒë√£ c√≥ tags, ƒë√£ sort theo match_score)
            riasec_scores: Vector 6 ƒëi·ªÉm [R, I, A, S, E, C] - thang ƒëi·ªÉm b·∫•t k·ª≥
            top_k: S·ªë ngh·ªÅ c·∫ßn tr·∫£ v·ªÅ (m·∫∑c ƒë·ªãnh 5)
        
        Returns:
            List ngh·ªÅ ƒë√£ filter, lu√¥n c·ªë g·∫Øng tr·∫£ ƒë·ªß top_k
        
        Logic ∆∞u ti√™n (STRICT - ch·ªâ L1 v√† L2):
            B∆∞·ªõc 1: L·∫•y L1 (dimension c√≥ ƒëi·ªÉm cao nh·∫•t)
            B∆∞·ªõc 2: L·∫•y L2 (dimension c√≥ ƒëi·ªÉm cao th·ª© 2)
            B∆∞·ªõc 3: Filter jobs:
                - ∆Øu ti√™n: ngh·ªÅ c√≥ PRIMARY tag = L1 (first char of any tag)
                - N·∫øu kh√¥ng ƒë·ªß: b·ªï sung ngh·ªÅ c√≥ PRIMARY tag = L2
                - N·∫øu v·∫´n thi·∫øu: fill b·∫±ng ngh·ªÅ c√≤n l·∫°i (theo match_score)
            
        QUAN TR·ªåNG:
            - Kh√¥ng d√πng top 3 dimension
            - Deterministic 100% (kh√¥ng random)
            - Gi·ªØ nguy√™n th·ª© t·ª± match_score trong m·ªói bucket
            - Tag matching: CH·ªà x√©t FIRST CHARACTER c·ªßa tag (primary dimension)
              V√≠ d·ª•: "RC" ‚Üí primary = "R", "AR" ‚Üí primary = "A"
            - Tie-breaking: n·∫øu 2 dimension c√≥ ƒëi·ªÉm b·∫±ng nhau, ∆∞u ti√™n theo th·ª© t·ª± R,I,A,S,E,C
        """
        if not jobs:
            logger.warning("No jobs to filter")
            return []
        
        if not riasec_scores or len(riasec_scores) != 6:
            logger.error("Invalid RIASEC scores, returning jobs by score only")
            return sorted(
                jobs,
                key=lambda x: (-x.get("match_score", 0.0), x.get("job_onet", "")),
            )[:top_k]
        
        # T√≠nh L1 v√† L2 t·ª´ RIASEC scores
        # Tie-breaking rule: n·∫øu ƒëi·ªÉm b·∫±ng nhau, ∆∞u ti√™n theo th·ª© t·ª± R,I,A,S,E,C (index nh·ªè h∆°n)
        dims = ["R", "I", "A", "S", "E", "C"]
        
        # Sort v·ªõi tie-breaker: (-score, index) ƒë·ªÉ index nh·ªè h∆°n ƒë∆∞·ª£c ∆∞u ti√™n khi score b·∫±ng nhau
        sorted_indices = sorted(
            range(6),
            key=lambda i: (-float(riasec_scores[i] or 0.0), i)
        )
        
        L1 = dims[sorted_indices[0]]
        L2 = dims[sorted_indices[1]]
        
        L1_score = float(riasec_scores[sorted_indices[0]] or 0.0)
        L2_score = float(riasec_scores[sorted_indices[1]] or 0.0)
        
        logger.info(
            f"üéØ RIASEC Top 2: L1={L1} ({L1_score:.4f}), L2={L2} ({L2_score:.4f})"
        )
        
        # Early return if jobs <= top_k
        if len(jobs) <= top_k:
            logger.warning(
                f"AI-core returned only {len(jobs)} careers, less than requested top_k={top_k}"
            )
            return sorted(
                jobs,
                key=lambda x: (-x.get("match_score", 0.0), x.get("job_onet", "")),
            )[:top_k]
        
        # Helper: l·∫•y PRIMARY dimension t·ª´ tag (first character)
        def get_primary_dim(tag: str) -> str:
            """
            L·∫•y primary dimension t·ª´ tag RIASEC.
            Tag format: "R", "RC", "RI", "AR", "SA", etc.
            Primary = first character.
            """
            tag = str(tag).strip().upper()
            if tag and tag[0] in dims:
                return tag[0]
            return ""
        
        # Ph√¢n lo·∫°i jobs v√†o 3 buckets: L1, L2, others
        # CRITICAL: Ch·ªâ x√©t PRIMARY dimension (first char) c·ªßa tag
        bucket_L1: List[Dict[str, Any]] = []
        bucket_L2: List[Dict[str, Any]] = []
        bucket_others: List[Dict[str, Any]] = []
        
        for job in jobs:
            raw_tags = job.get("tags") or []
            
            # L·∫•y t·∫•t c·∫£ primary dimensions t·ª´ tags
            primary_dims = set()
            for tag in raw_tags:
                if tag is not None:
                    pd = get_primary_dim(tag)
                    if pd:
                        primary_dims.add(pd)
            
            # Check n·∫øu primary dimension = L1 ho·∫∑c L2
            has_L1 = L1 in primary_dims
            has_L2 = L2 in primary_dims
            
            # Ph√¢n lo·∫°i: ∆∞u ti√™n L1 tr∆∞·ªõc, n·∫øu kh√¥ng c√≥ L1 th√¨ x√©t L2
            if has_L1:
                bucket_L1.append(job)
            elif has_L2:
                bucket_L2.append(job)
            else:
                bucket_others.append(job)
        
        # Sort t·ª´ng bucket theo match_score gi·∫£m d·∫ßn v·ªõi tie-breaker deterministic
        def sort_key(x):
            return (-x.get("match_score", 0.0), x.get("job_onet", ""))
        
        bucket_L1.sort(key=sort_key)
        bucket_L2.sort(key=sort_key)
        bucket_others.sort(key=sort_key)
        
        logger.info(
            f"üìä Bucket sizes: L1({L1})={len(bucket_L1)}, L2({L2})={len(bucket_L2)}, "
            f"others={len(bucket_others)}"
        )
        
        # Gh√©p k·∫øt qu·∫£ theo th·ª© t·ª±: L1 ‚Üí L2 ‚Üí others
        result: List[Dict[str, Any]] = []
        
        # B∆∞·ªõc 1: L·∫•y t·ª´ L1
        for job in bucket_L1:
            if len(result) >= top_k:
                break
            result.append(job)
        
        # B∆∞·ªõc 2: N·∫øu ch∆∞a ƒë·ªß, l·∫•y t·ª´ L2
        if len(result) < top_k:
            for job in bucket_L2:
                if len(result) >= top_k:
                    break
                result.append(job)
        
        # B∆∞·ªõc 3: N·∫øu v·∫´n ch∆∞a ƒë·ªß, l·∫•y t·ª´ others
        if len(result) < top_k:
            for job in bucket_others:
                if len(result) >= top_k:
                    break
                result.append(job)
        
        # Logging chi ti·∫øt
        logger.info(f"‚úÖ Final {len(result)} careers after L1/L2 filter:")
        for i, job in enumerate(result[:top_k], 1):
            title = job.get("title_en") or job.get("title_vi") or "Unknown"
            tags = job.get("tags", [])
            score = job.get("match_score", 0.0)
            
            # Determine bucket based on primary dimension
            raw_tags = job.get("tags") or []
            primary_dims = set()
            for tag in raw_tags:
                if tag is not None:
                    pd = get_primary_dim(tag)
                    if pd:
                        primary_dims.add(pd)
            
            bucket_name = "other"
            if L1 in primary_dims:
                bucket_name = f"L1({L1})"
            elif L2 in primary_dims:
                bucket_name = f"L2({L2})"
            
            logger.info(
                f"  #{i} [{bucket_name:8}] {title[:35]:<35} | "
                f"Tags: {str(tags):<15} | Score: {score:.4f}"
            )
        
        # Warning n·∫øu L1 bucket qu√° √≠t
        if len(bucket_L1) < top_k:
            l2_in_result = sum(1 for j in result if L2 in set(
                get_primary_dim(t) for t in (j.get("tags") or []) if t
            ))
            others_in_result = len(result) - len(bucket_L1) - l2_in_result
            logger.warning(
                f"‚ö†Ô∏è  Only {len(bucket_L1)}/{top_k} careers match L1={L1}. "
                f"Filled with L2={L2} ({l2_in_result}) and others ({others_in_result})"
            )
        
        return result

    # ====================================================================== #
    # 3. Public API ‚Äì get_main_recommendations
    # ====================================================================== #

    def get_main_recommendations(
        self,
        db: Session,
        assessment_id: int,
        top_k: int = 20,
    ) -> Dict[str, Any]:
        # L·∫•y nhi·ªÅu h∆°n ƒë·ªÉ c√≤n room cho join + filter
        # TƒÉng t·ª´ 4x l√™n 10x ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªß ngh·ªÅ kh·ªõp nh√£n RIASEC
        internal_top_k = max(top_k * 10, 100)

        # 1) Map assessment -> user_id
        user_id = self._get_user_from_assessment(db, assessment_id)
        if user_id is None:
            raise RuntimeError(f"Assessment {assessment_id} not found or invalid")

        # 2) G·ªçi AI-core
        scored = self._call_ai_core_top_careers(assessment_id, internal_top_k)
        if not scored:
            return {"request_id": None, "items": []}

        # 3) Snapshot traits c·ªßa **ch√≠nh assessment n√†y**
        traits = self._load_traits_snapshot(db, assessment_id)
        riasec_values = traits.get("riasec_values")
        top_dim = traits.get("riasec_top_dim")
        
        # STRICT: B·∫Øt bu·ªôc ph·∫£i c√≥ RIASEC values
        if not riasec_values or len(riasec_values) != 6:
            logger.error(f"Assessment {assessment_id}: Missing RIASEC values for user {user_id}")
            raise RuntimeError(
                f"Missing RIASEC traits for user {user_id}. "
                "User must complete RIASEC assessment first."
            )

        logger.info(
            f"Assessment {assessment_id}: top_interest={top_dim}, "
            f"AI-core returned {len(scored)} careers"
        )

        # 4) Join meta ƒë·ªÉ l·∫•y slug/title/tags
        items_with_meta = self._attach_career_meta(db, scored)

        logger.info(
            f"Assessment {assessment_id}: {len(items_with_meta)} careers after metadata join"
        )
        
        # DEBUG: Log first 10 careers with tags
        logger.info(f"üìã First 10 careers with tags (before filter):")
        for i, item in enumerate(items_with_meta[:10], 1):
            title = item.get("title_en") or item.get("title_vi") or "Unknown"
            tags = item.get("tags", [])
            score = item.get("match_score", 0.0)
            logger.info(f"  {i}. {title[:40]:<40} | Tags: {tags} | Score: {score:.3f}")

        # 5) Filter theo RIASEC L1/L2 (NEW LOGIC - ch·ªâ d√πng top 2 dimensions)
        items_filtered = self._filter_by_riasec_top2(
            jobs=items_with_meta,
            riasec_scores=riasec_values,
            top_k=top_k,
        )

        logger.info(
            f"Assessment {assessment_id}: {len(items_filtered)} careers after L1/L2 filter"
        )

        # 6) Chu·∫©n ho√° display_match
        self._apply_display_match(items_filtered)

        # 7) Generate request_id + ƒë√°nh position
        # NOTE: Impression logging ƒë√£ chuy·ªÉn sang FE ƒë·ªÉ tr√°nh double-count
        # FE s·∫Ω g·ªçi /api/analytics/career-event khi user m·ªü tab Career Matches
        request_id = str(uuid.uuid4())

        for idx, it in enumerate(items_filtered, start=1):
            it["position"] = idx

        # 8) Save top 5 recommendations to core.career_recommendations table
        # Only save when fetching full recommendations (top_k >= 5), not for dashboard preview (top_k=3)
        if top_k >= 5:
            self._save_career_recommendations(db, user_id, assessment_id, items_filtered[:5])

        return {
            "request_id": request_id,
            "items": items_filtered,
        }

    def _save_career_recommendations(
        self,
        db: Session,
        user_id: int,
        assessment_id: int,
        items: List[Dict[str, Any]],
    ) -> None:
        """
        Save top career recommendations to core.career_recommendations table.
        This persists the recommendations for history tracking.
        """
        if not items:
            return
        
        try:
            # First, delete any existing recommendations for this assessment
            db.execute(
                text(
                    """
                    DELETE FROM core.career_recommendations
                    WHERE assessment_id = :assessment_id
                    """
                ),
                {"assessment_id": assessment_id}
            )
            
            # Insert new recommendations
            for item in items:
                # Get career_id from core.careers table using slug or onet_code
                career_id_result = db.execute(
                    text(
                        """
                        SELECT id FROM core.careers
                        WHERE slug = :slug OR onet_code = :onet_code
                        LIMIT 1
                        """
                    ),
                    {
                        "slug": item.get("slug"),
                        "onet_code": item.get("job_onet") or item.get("career_id")
                    }
                ).fetchone()
                
                if career_id_result:
                    career_id = career_id_result[0]
                    db.execute(
                        text(
                            """
                            INSERT INTO core.career_recommendations
                                (user_id, assessment_id, career_id, score, rank)
                            VALUES
                                (:user_id, :assessment_id, :career_id, :score, :rank)
                            """
                        ),
                        {
                            "user_id": user_id,
                            "assessment_id": assessment_id,
                            "career_id": career_id,
                            "score": item.get("display_match") or item.get("match_score", 0.0),
                            "rank": item.get("position", 0)
                        }
                    )
            
            db.commit()
            logger.info(f"Saved {len(items)} career recommendations for assessment {assessment_id}")
            
        except Exception as e:
            logger.error(f"Failed to save career recommendations: {e}")
            db.rollback()

    # ====================================================================== #
    # 4. AI-core integration
    # ====================================================================== #

    def _call_ai_core_top_careers(
        self,
        assessment_id: int,
        top_k: int,
    ) -> List[Dict[str, Any]]:
        url = f"{AI_CORE_BASE_URL}/recs/top_careers"
        payload = {"assessment_id": assessment_id, "top_k": top_k}

        try:
            with httpx.Client(timeout=5.0) as client:
                resp = client.post(url, json=payload)
                
            if resp.status_code != 200:
                print(f"AI-core error {resp.status_code}: {resp.text}")
                return self._get_fallback_recommendations(top_k)

            data = resp.json()
            items = data.get("items", [])
            if not isinstance(items, list):
                print("AI-core returned invalid format")
                return self._get_fallback_recommendations(top_k)

        except Exception as e:
            print(f"AI-core not reachable: {e}")
            return self._get_fallback_recommendations(top_k)

        out: List[Dict[str, Any]] = []
        for it in items:
            cid = it.get("career_id")
            score = it.get("final_score")
            if cid is None or score is None:
                continue
            out.append(
                {
                    "career_id": str(cid),
                    "final_score": float(score),
                }
            )

        out.sort(key=lambda x: x["final_score"], reverse=True)
        return out

    # ====================================================================== #
    # 5. Postgres helpers
    # ====================================================================== #

    def _get_user_from_assessment(
        self,
        db: Session,
        assessment_id: int,
    ) -> Optional[int]:
        sql = text(
            """
            SELECT user_id
            FROM core.assessments
            WHERE id = :aid
            LIMIT 1
            """
        )
        row = db.execute(sql, {"aid": assessment_id}).mappings().first()
        if not row:
            return None
        uid = row.get("user_id")
        return int(uid) if uid is not None else None

    def _load_traits_snapshot(
        self,
        db: Session,
        assessment_id: int,
    ) -> Dict[str, Any]:
        """
        L·∫•y RIASEC scores t·ª´ assessment c√πng session v·ªõi assessment_id hi·ªán t·∫°i.
        N·∫øu assessment_id l√† RIASEC th√¨ d√πng lu√¥n scores c·ªßa n√≥.
        N·∫øu kh√¥ng, t√¨m RIASEC assessment trong c√πng session (c√πng user, trong 5 ph√∫t).
        
        ƒê·∫£m b·∫£o:
        - L·∫•y RIASEC assessment t·ª´ C√ôNG SESSION v·ªõi assessment_id
        - Th·ª© t·ª± R, I, A, S, E, C ƒë√∫ng
        - ƒêi·ªÉm g·ªëc thang 1-5 (ch∆∞a normalize)
        - Deterministic 100%
        - M·ªói b√†i test d√πng RIASEC c·ªßa ch√≠nh session ƒë√≥
        """
        # 1) L·∫•y user_id v√† session_id t·ª´ assessment
        sql = text(
            """
            SELECT user_id, session_id
            FROM core.assessments
            WHERE id = :aid
            LIMIT 1
            """
        )
        row = db.execute(sql, {"aid": assessment_id}).mappings().first()
        if not row:
            logger.error(f"Assessment {assessment_id} not found in DB")
            return {"riasec_top_dim": None, "riasec_values": None}
        
        user_id = row.get("user_id")
        session_id = row.get("session_id")
        if not user_id:
            logger.error(f"Assessment {assessment_id} has no user_id")
            return {"riasec_top_dim": None, "riasec_values": None}
        
        # 2) L·∫•y RIASEC scores t·ª´ assessment C√ôNG SESSION (kh√¥ng ph·∫£i m·ªõi nh·∫•t c·ªßa user)
        riasec_row = None
        
        if session_id:
            # L·∫•y RIASEC assessment t·ª´ c√πng session
            sql_riasec = text(
                """
                SELECT scores
                FROM core.assessments
                WHERE session_id = :sid AND a_type = 'RIASEC'
                LIMIT 1
                """
            )
            riasec_row = db.execute(sql_riasec, {"sid": session_id}).mappings().first()
            logger.info(f"Assessment {assessment_id}: Looking for RIASEC in session {session_id}")
        
        # Fallback: n·∫øu kh√¥ng c√≥ session_id ho·∫∑c kh√¥ng t√¨m th·∫•y RIASEC trong session
        if not riasec_row or not riasec_row.get("scores"):
            # N·∫øu assessment_id ch√≠nh l√† RIASEC, d√πng lu√¥n
            sql_check = text(
                """
                SELECT scores, a_type
                FROM core.assessments
                WHERE id = :aid
                LIMIT 1
                """
            )
            check_row = db.execute(sql_check, {"aid": assessment_id}).mappings().first()
            if check_row and check_row.get("a_type") == "RIASEC":
                riasec_row = check_row
                logger.info(f"Assessment {assessment_id} is itself a RIASEC assessment")
        
        if not riasec_row or not riasec_row.get("scores"):
            logger.error(f"Assessment {assessment_id}: No RIASEC assessment found in session {session_id}")
            return {"riasec_top_dim": None, "riasec_values": None}
        
        # 4) Parse scores dict ‚Üí vector theo th·ª© t·ª± R, I, A, S, E, C
        dims = ["R", "I", "A", "S", "E", "C"]
        
        riasec_vec: List[float] = []
        for dim in dims:
            score = scores_dict.get(dim)
            if score is None:
                logger.error(f"User {user_id} missing RIASEC dimension {dim}")
                return {"riasec_top_dim": None, "riasec_values": None}
            riasec_vec.append(float(score))
        
        # 5) T√≠nh top_dim v·ªõi tie-breaking rule: R,I,A,S,E,C (index nh·ªè h∆°n ∆∞u ti√™n)
        # Sort v·ªõi (-score, index) ƒë·ªÉ ƒë·∫£m b·∫£o deterministic khi c√≥ tie
        sorted_indices = sorted(range(6), key=lambda i: (-riasec_vec[i], i))
        top_dim = dims[sorted_indices[0]]
        
        # DEBUG: Log RIASEC scores (thang 1-5 g·ªëc)
        logger.info(f"Assessment {assessment_id} (user {user_id}) RIASEC scores (1-5 scale):")
        for i, dim in enumerate(dims):
            marker = "üëâ" if i == sorted_indices[0] else "  "
            score = riasec_vec[i]
            logger.info(f"  {marker} {dim}: {score:.3f}")
        
        logger.info(f"üéØ Assessment {assessment_id} TOP INTEREST: {top_dim}")
        
        return {
            "riasec_top_dim": top_dim,
            "riasec_values": riasec_vec,  # Thang 1-5 g·ªëc, th·ª© t·ª± R,I,A,S,E,C
            "user_id": user_id,
        }

    def _load_career_meta(self, db: Session, onet_code: str) -> Dict[str, Any]:
        sql = text(
            """
            SELECT
                c.id,
                c.slug,
                c.onet_code,
                c.title_vi,
                c.title_en,
                c.short_desc_vn,
                c.short_desc_en,
                NULL::int AS job_zone,
                COALESCE(
                    array_agg(rl.code) FILTER (WHERE rl.code IS NOT NULL),
                    '{}'
                ) AS riasec_codes
            FROM core.careers AS c
            LEFT JOIN core.career_riasec_map AS m
                ON m.career_id = c.id
            LEFT JOIN core.riasec_labels AS rl
                ON rl.id = m.label_id
            WHERE c.onet_code = :cid
            GROUP BY
                c.id, c.slug, c.onet_code,
                c.title_vi, c.title_en,
                c.short_desc_vn, c.short_desc_en
            LIMIT 1
            """
        )
        row = db.execute(sql, {"cid": onet_code}).mappings().first()
        if not row:
            return {}

        d = dict(row)
        if isinstance(d.get("riasec_codes"), (list, tuple)):
            d["riasec_codes"] = [str(x) for x in d["riasec_codes"] if x is not None]
        else:
            d["riasec_codes"] = []
        return d

    def _get_fallback_recommendations(self, top_k: int) -> List[Dict[str, Any]]:
        """
        Fallback recommendations khi AI-core kh√¥ng available
        Tr·∫£ v·ªÅ mock data v·ªõi O*NET codes th·ª±c t·∫ø
        """
        fallback_careers = [
            {"career_id": "15-1252.00", "final_score": 0.92},  # Software Developers
            {"career_id": "11-3021.00", "final_score": 0.88},  # Computer and Information Systems Managers
            {"career_id": "15-1299.08", "final_score": 0.85},  # Web Developers
            {"career_id": "15-1244.00", "final_score": 0.82},  # Network and Computer Systems Administrators
            {"career_id": "15-1212.00", "final_score": 0.79},  # Information Security Analysts
            {"career_id": "11-1011.00", "final_score": 0.76},  # Chief Executives
            {"career_id": "13-1161.00", "final_score": 0.73},  # Market Research Analysts
            {"career_id": "25-1022.00", "final_score": 0.70},  # Mathematical Science Teachers
            {"career_id": "19-3051.00", "final_score": 0.67},  # Urban and Regional Planners
            {"career_id": "27-3031.00", "final_score": 0.64},  # Public Relations Specialists
        ]
        
        return fallback_careers[:top_k]

    # ====================================================================== #
    # 6. display_match + analytics
    # ====================================================================== #

    def _apply_display_match(self, items: List[Dict[str, Any]]) -> None:
        if not items:
            return

        scores = [float(it.get("match_score", 0.0)) for it in items]
        min_s = min(scores)
        max_s = max(scores)

        if max_s <= min_s:
            for it in items:
                it["display_match"] = 95.0
        else:
            for it in items:
                s = float(it.get("match_score", 0.0))
                normalized = (s - min_s) / (max_s - min_s)
                display = 70.0 + normalized * 25.0
                it["display_match"] = round(display, 1)

        for idx, it in enumerate(items, start=1):
            it["position"] = idx

    def _log_impressions(
        self,
        db: Session,
        user_id: int,
        items: List[Dict[str, Any]],
        request_id: str,
    ) -> None:
        if not items:
            return

        sql = text(
            """
            INSERT INTO analytics.career_events
                (user_id, job_id, event_type, rank_pos, score_shown, source, ref)
            VALUES
                (:user_id, :job_id, :event_type, :rank_pos, :score_shown, :source, :ref)
            """
        )

        for it in items:
            job_onet = it.get("job_onet") or it.get("career_id")
            db.execute(
                sql,
                {
                    "user_id": user_id,
                    "job_id": job_onet,
                    "event_type": "impression",
                    "rank_pos": it.get("position", 0),
                    "score_shown": float(it.get("match_score", 0.0)),
                    "source": "neumf",
                    "ref": request_id,
                },
            )
        db.commit()

    # ====================================================================== #
    # 7. Click logging
    # ====================================================================== #

    def _slug_to_onet(self, db: Session, career_id: str) -> str:
        sql = text(
            """
            SELECT
                CASE
                    WHEN c.onet_code = :cid THEN c.onet_code
                    WHEN c.slug = :cid THEN c.onet_code
                    ELSE NULL
                END AS onet_code
            FROM core.careers AS c
            WHERE c.slug = :cid OR c.onet_code = :cid
            LIMIT 1
            """
        )
        row = db.execute(sql, {"cid": career_id}).mappings().first()
        if row and row.get("onet_code"):
            return str(row["onet_code"])
        return career_id

class CareerEventsService:
    """
    Service ghi l·∫°i c√°c event CLICK cho recommendation
    (impression v·∫´n do RecService._log_impressions lo).
    """

    def __init__(self, db: Session) -> None:
        self.db = db

    def log_click(
        self,
        *,
        user_id: Optional[int],
        session_id: Optional[str],
        job_onet: str,
        rank_pos: Optional[int],
        score_shown: Optional[float],
        request_id: Optional[str],
    ) -> None:
        """
        Ghi 1 record 'click' v√†o analytics.career_events
        - job_onet: O*NET code (vd '49-9097.00')
        - rank_pos: v·ªã tr√≠ trong list (#1, #2, #3‚Ä¶)
        - score_shown: % match / score hi·ªÉn th·ªã cho user
        - request_id: tracking id t·ª´ /api/recommendations
        """
        self.db.execute(
            text(
                """
                INSERT INTO analytics.career_events
                    (user_id, session_id, job_id, event_type,
                     rank_pos, score_shown, source, ref)
                VALUES
                    (:user_id,
                     :session_id,
                     :job_id,
                     'click',
                     :rank_pos,
                     :score,
                     'neumf',
                     :ref)
                """
            ),
            {
                "user_id": user_id,
                "session_id": session_id,   # uuid text, Postgres t·ª± cast
                "job_id": job_onet,
                "rank_pos": rank_pos,
                "score": score_shown,
                "ref": request_id,
            },
        )
        self.db.commit()

