# ðŸ¤– AI-Core â€” MÃ´-Ä‘un TrÃ­ Tuá»‡ NhÃ¢n Táº¡o cho Há»‡ thá»‘ng Gá»£i Ã½ Nghá» nghiá»‡p CÃ¡ nhÃ¢n hÃ³a

### (AI-Based Career Recommendation System)

---

## ðŸ“˜ Tá»•ng quan

**AI-Core** lÃ  mÃ´-Ä‘un trung tÃ¢m xá»­ lÃ½ **TrÃ­ tuá»‡ nhÃ¢n táº¡o (AI)** cho dá»± Ã¡n
ðŸ§  *AI-Based Career Recommendation System* (Há»‡ thá»‘ng gá»£i Ã½ nghá» nghiá»‡p cÃ¡ nhÃ¢n hÃ³a).

Má»¥c tiÃªu chÃ­nh cá»§a mÃ´-Ä‘un:

* PhÃ¢n tÃ­ch **vÄƒn báº£n tá»± luáº­n (essay)** báº±ng **PhoBERT / vi-SBERT** Ä‘á»ƒ rÃºt ra Ä‘áº·c Ä‘iá»ƒm tÃ¢m lÃ½, hÃ nh vi.
* Gá»£i Ã½ **nghá» nghiá»‡p phÃ¹ há»£p** dá»±a trÃªn Ä‘áº·c Ä‘iá»ƒm tÃ­nh cÃ¡ch **Big Five** + **sá»Ÿ thÃ­ch RIASEC**.
* XÃ¢y dá»±ng **bá»™ tÃ¬m kiáº¿m nghá» tÆ°Æ¡ng tá»±** báº±ng **Vector Retrieval (pgvector)**.
* Xáº¿p háº¡ng & tá»‘i Æ°u gá»£i Ã½ báº±ng **NeuMF (Neural Matrix Factorization)** vÃ  **Reinforcement Learning (Contextual Bandit)**.

---

## âš™ï¸ Kiáº¿n trÃºc thÆ° má»¥c

```
ai-core/
â”œâ”€ src/                         # Source code chÃ­nh
â”‚  â”œâ”€ nlp/                      # NLP: PhoBERT / vi-SBERT cho embedding, inference
â”‚  â”‚  â”œâ”€ encode_texts.py
â”‚  â”‚  â”œâ”€ infer_traits.py
â”‚  â”‚  â””â”€ tokenizer_utils.py
â”‚  â”‚
â”‚  â”œâ”€ retrieval/                # Truy váº¥n nghá» báº±ng FAISS hoáº·c pgvector
â”‚  â”‚  â”œâ”€ search_pgvector.py
â”‚  â”‚  â””â”€ build_index.py
â”‚  â”‚
â”‚  â”œâ”€ recommend/                # Gá»£i Ã½ nghá» nghiá»‡p (NeuMF, RL bandit)
â”‚  â”‚  â”œâ”€ rank_neumf.py
â”‚  â”‚  â”œâ”€ rl_bandit.py
â”‚  â”‚  â””â”€ utils.py
â”‚  â”‚
â”‚  â”œâ”€ utils/                    # Tiá»‡n Ã­ch chung (log, config, vector ops,â€¦)
â”‚  â”‚  â”œâ”€ io_utils.py
â”‚  â”‚  â””â”€ metrics.py
â”‚  â”‚
â”‚  â””â”€ __init__.py
â”‚
â”œâ”€ configs/                     # Cáº¥u hÃ¬nh mÃ´ hÃ¬nh & pipeline
â”‚  â”œâ”€ encode.yaml
â”‚  â”œâ”€ nlp.yaml
â”‚  â””â”€ schema.yaml
â”‚
â”œâ”€ models/                      # MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n (PhoBERT, NeuMF, RL)
â”‚  â””â”€ (bá» trá»‘ng / .gitkeep)
â”‚
â”œâ”€ notebooks/                   # Notebook thá»­ nghiá»‡m & huáº¥n luyá»‡n
â”‚  â”œâ”€ training_phobert.ipynb
â”‚  â”œâ”€ retrieval_indexing.ipynb
â”‚  â””â”€ neumf_experiments.ipynb
â”‚
â”œâ”€ data/                        # Dá»¯ liá»‡u máº«u hoáº·c embedding nÃ©n
â”‚  â”œâ”€ embeddings/
â”‚  â”œâ”€ jobs_catalog/
â”‚  â””â”€ ...
â”‚
â”œâ”€ tests/                       # Unit test cho tá»«ng module
â”‚  â”œâ”€ test_infer_traits.py
â”‚  â”œâ”€ test_search_pgvector.py
â”‚  â””â”€ test_neumf.py
â”‚
â”œâ”€ pyproject.toml               # Äá»‹nh nghÄ©a package (PEP 621)
â”œâ”€ requirements.txt             # ThÆ° viá»‡n Python
â””â”€ README.md                    # TÃ i liá»‡u nÃ y
```

---

## ðŸ“¦ CÃ i Ä‘áº·t

### CÃ¡ch 1 â€” CÃ i trong nhÃ¡nh main (Ä‘Æ°á»£c backend import)

```bash
pip install -e ./packages/ai-core
```

### CÃ¡ch 2 â€” Cháº¡y Ä‘á»™c láº­p (khi phÃ¡t triá»ƒn mÃ´ hÃ¬nh)

```bash
python -m venv .venv
source .venv/bin/activate    # hoáº·c .\.venv\Scripts\activate trÃªn Windows
pip install -r requirements.txt
```

> âš ï¸ Gá»£i Ã½: giá»¯ mÃ´ hÃ¬nh `.pt` / `.bin` trong thÆ° má»¥c riÃªng vÃ  **Ä‘á»«ng commit lÃªn Git**
> â†’ ÄÃ£ cÃ³ sáºµn `.gitignore` cho `models/` vÃ  `data/`

---

## ðŸ§  Chá»©c nÄƒng chÃ­nh

| Module                        | Má»¥c tiÃªu                                                | MÃ´ táº£                                                  |
| ----------------------------- | ------------------------------------------------------- | ------------------------------------------------------ |
| **nlp.encode_texts**          | TrÃ­ch xuáº¥t embedding vÄƒn báº£n báº±ng **PhoBERT/vi-SBERT**  | DÃ¹ng cho retrieval & phÃ¢n tÃ­ch bÃ i luáº­n                |
| **nlp.infer_traits**          | Suy luáº­n Ä‘iá»ƒm RIASEC + Big Five tá»« bÃ i luáº­n             | Model fine-tuned PhoBERT                               |
| **retrieval.search_pgvector** | TÃ¬m nghá» tÆ°Æ¡ng tá»± trong **Postgres+pgvector**           | So khá»›p embedding nghá» vá»›i ngÆ°á»i dÃ¹ng                  |
| **recommend.rank_neumf**      | Xáº¿p háº¡ng nghá» báº±ng **NeuMF**                            | Dá»±a trÃªn vector nghá» vÃ  ngÆ°á»i dÃ¹ng                     |
| **recommend.rl_bandit**       | Cáº­p nháº­t & tá»‘i Æ°u gá»£i Ã½ báº±ng **Reinforcement Learning** | Contextual Bandit (epsilon-greedy / Thompson sampling) |

---

## ðŸ§ª VÃ­ dá»¥ cháº¡y thá»­

### 1ï¸âƒ£ Táº¡o embedding vÄƒn báº£n

```bash
python -m src.nlp.encode_texts --input data/raw/essays.csv --output data/embeddings/essays.npy
```

### 2ï¸âƒ£ Gá»i PhoBERT infer

```bash
python -m src.nlp.infer_traits --essay "TÃ´i thÃ­ch nghiÃªn cá»©u vÃ  giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» logic."
```

### 3ï¸âƒ£ TÃ¬m kiáº¿m nghá» tÆ°Æ¡ng tá»± báº±ng pgvector

```bash
python -m src.retrieval.search_pgvector \
  --db_url "postgresql://postgres:123456@localhost:5433/career_ai" \
  --query_text "phÃ¢n tÃ­ch dá»¯ liá»‡u, trá»±c quan hÃ³a BI" \
  --topk 10
```

### 4ï¸âƒ£ Xáº¿p háº¡ng gá»£i Ã½ báº±ng NeuMF

```bash
python -m src.recommend.rank_neumf --user_id 42 --topk 5
```

---

## ðŸ§° ThÆ° viá»‡n sá»­ dá»¥ng

| NhÃ³m           | ThÆ° viá»‡n                                         | Má»¥c Ä‘Ã­ch                    |
| -------------- | ------------------------------------------------ | --------------------------- |
| NLP            | `transformers`, `torch`, `sentence-transformers` | PhoBERT, vi-SBERT           |
| ML             | `numpy`, `scikit-learn`, `pandas`                | Tiá»n xá»­ lÃ½ & tÃ­nh Ä‘iá»ƒm      |
| DB             | `psycopg2`, `sqlalchemy`                         | Káº¿t ná»‘i Postgres / pgvector |
| Recommendation | `implicit`, `surprise`                           | NeuMF & CF baseline         |
| RL             | `gymnasium`, `banditpylib`                       | Contextual Bandit           |
| Utility        | `yaml`, `tqdm`, `typer`                          | Cáº¥u hÃ¬nh, CLI, progress     |

---

## ðŸ”¬ MÃ´i trÆ°á»ng & Cáº¥u hÃ¬nh

File `.env.example`:

```env
DATABASE_URL=postgresql://postgres:123456@localhost:5433/career_ai
AI_MODELS_DIR=./models
DEVICE=cuda
LOG_LEVEL=info
```

File `configs/nlp.yaml` (vÃ­ dá»¥):

```yaml
model_name: vinai/phobert-base
embedding_dim: 768
max_length: 256
batch_size: 16
```

---

## ðŸ§© TÃ­ch há»£p vá»›i Backend (FastAPI)

Backend cÃ³ thá»ƒ gá»i trá»±c tiáº¿p:

```python
from ai_core.src.nlp.infer_traits import infer_essay_traits

traits = infer_essay_traits("TÃ´i thÃ­ch lÃ m viá»‡c nhÃ³m vÃ  giao tiáº¿p vá»›i má»i ngÆ°á»i.")
print(traits)
```

> Trong `.env` cá»§a backend:
>
> ```
> AI_MODELS_DIR=packages/ai-core/models
> ```

---

## ðŸ§± Chuáº©n hoÃ¡ & CI

### Lint & Format

```bash
ruff check .
black .
```

### Test

```bash
pytest -q
```

### Cáº¥u hÃ¬nh CI (GitHub Actions)

Tá»± Ä‘á»™ng kiá»ƒm tra:

* CÃ i dependencies (`pip install -r requirements.txt`)
* Kiá»ƒm tra `ruff`, `black`, `pytest`

---

## ðŸ§­ Äá»‹nh hÆ°á»›ng phÃ¡t triá»ƒn

| Giai Ä‘oáº¡n          | Má»¥c tiÃªu                                        | MÃ´ táº£                                           |
| ------------------ | ----------------------------------------------- | ----------------------------------------------- |
| **MVP (hiá»‡n táº¡i)** | PhoBERT + NeuMF + pgvector                      | Káº¿t há»£p trong nhÃ¡nh main cÃ¹ng backend             |
| **Phase 2**        | TÃ¡ch ai-core thÃ nh service riÃªng (FastAPI/gRPC) | Cho phÃ©p scale Ä‘á»™c láº­p inference                |
| **Phase 3**        | RL Online Learning                              | Thu tháº­p feedback ngÆ°á»i dÃ¹ng & tá»‘i Æ°u dáº§n gá»£i Ã½ |
| **Phase 4**        | Fine-tune PhoBERT + NeuMF domain Viá»‡t Nam       | DÃ¹ng dá»¯ liá»‡u nghá» nghiá»‡p má»Ÿ rá»™ng                |

---

## ðŸ“Ž Giáº¥y phÃ©p

Dá»± Ã¡n phÃ¡t hÃ nh theo **Apache License 2.0**
Â© 2025 - NhÃ³m NghiÃªn cá»©u Khoa há»c Ká»¹ sÆ° Pháº§n má»m - Äáº¡i há»c Duy TÃ¢n.


---

> ðŸ“Œ *Má»i thay Ä‘á»•i á»Ÿ nhÃ¡nh `AI` sáº½ Ä‘Æ°á»£c Ä‘á»“ng bá»™ vá» nhÃ¡nh main qua lá»‡nh:*
>
> ```bash
> git subtree pull --prefix=packages/ai-core origin AI --squash
> ```
