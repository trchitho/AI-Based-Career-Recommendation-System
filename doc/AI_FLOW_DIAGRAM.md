# AI Flow Diagram - Career Recommendation System

## S∆° ƒë·ªì lu·ªìng ch·∫°y AI (C·∫≠p nh·∫≠t theo code th·ª±c t·∫ø)

```mermaid
flowchart TB
    subgraph FE["üñ•Ô∏è Frontend (React)"]
        UI_INPUT["User Input<br/>(Essay + Test RIASEC/Big5)"]
        UI_RESULTS["Results Page<br/>(Spider Chart + Recommendations)"]
    end

    subgraph BE["‚öôÔ∏è Backend (FastAPI :8000)"]
        BE_ASSESS["routes_assessments.py<br/>/api/assessments/*"]
        BE_REC["routes_recommendations.py<br/>/api/recommendations"]
        BE_SERVICE["recommendation/service.py<br/>- _call_ai_core_top_careers()<br/>- _filter_by_riasec_top2()<br/>- _attach_career_meta()"]
    end

    subgraph AI["ü§ñ AI-Core (FastAPI :9000)"]
        direction TB
        
        subgraph TRAITS["üìù Traits Inference"]
            TRAITS_API["routes_traits.py<br/>POST /ai/infer_user_traits"]
            ESSAY_INFER["essay_infer.py<br/>infer_user_traits()"]
            
            subgraph MODELS["PhoBERT Models"]
                RIASEC_MODEL["riasec_phobert/best.pt<br/>‚Üí 6 scores (R,I,A,S,E,C)"]
                BIG5_MODEL["big5_phobert/best.pt<br/>‚Üí 5 scores (O,C,E,A,N)"]
                SBERT["vi_sbert_768/<br/>‚Üí embedding 768D"]
            end
        end
        
        subgraph RECS["üéØ Recommendations"]
            RECS_API["routes_recs.py<br/>POST /recs/top_careers"]
            LOADER["traits/loader.py<br/>load_traits_and_embedding_for_assessment()"]
            
            subgraph RETRIEVAL["üìä Retrieval (B3)"]
                PGVECTOR["service_pgvector.py<br/>search_candidates_for_embedding()"]
            end
            
            subgraph RANKING["üèÜ Ranking (B4)"]
                NEUMF["neumf/infer.py<br/>infer_scores()"]
                COLDSTART["Cold-start Fallback<br/>(use retrieval scores)"]
            end
            
            subgraph BANDIT["üé∞ Bandit (B5) - STUB"]
                BANDIT_STUB["bandit.py<br/>recommend_with_bandit()<br/>(hi·ªán ch·ªâ sort by rank_score)"]
            end
        end
    end

    subgraph DB["üóÑÔ∏è PostgreSQL + pgvector"]
        direction LR
        
        subgraph CORE["Schema: core"]
            T_ASSESS["assessments<br/>assessment_sessions<br/>assessment_responses"]
            T_ESSAYS["essays"]
            T_CAREERS["careers<br/>career_riasec_map"]
            T_RECS["career_recommendations"]
        end
        
        subgraph AI_SCHEMA["Schema: ai"]
            T_EMB["user_embeddings<br/>(emb vector(768), source='essay')"]
            T_TRAITS["user_trait_preds<br/>(riasec_pred, big5_pred)"]
            T_JOBS["retrieval_jobs_visbert<br/>(job_id, embedding vector(768))"]
        end
    end

    %% Flow 1: User l√†m test + Essay
    UI_INPUT -->|"1. Submit Test"| BE_ASSESS
    BE_ASSESS -->|"2. Save responses"| T_ASSESS
    
    UI_INPUT -->|"3. Submit Essay"| BE_ASSESS
    BE_ASSESS -->|"4. Save essay"| T_ESSAYS
    
    %% Flow 2: AI Scoring
    BE_ASSESS -->|"5. POST /ai/infer_user_traits"| TRAITS_API
    TRAITS_API --> ESSAY_INFER
    ESSAY_INFER --> RIASEC_MODEL
    ESSAY_INFER --> BIG5_MODEL
    ESSAY_INFER --> SBERT
    
    TRAITS_API -->|"6. Return traits + embedding"| BE_ASSESS
    BE_ASSESS -->|"7. Save traits"| T_TRAITS
    BE_ASSESS -->|"8. Save embedding"| T_EMB
    
    %% Flow 3: Get Recommendations
    UI_INPUT -->|"9. GET /api/recommendations"| BE_REC
    BE_REC --> BE_SERVICE
    BE_SERVICE -->|"10. POST /recs/top_careers"| RECS_API
    
    %% AI-Core internal flow
    RECS_API --> LOADER
    LOADER -->|"11. Load embedding"| T_EMB
    LOADER --> PGVECTOR
    
    PGVECTOR -->|"12. pgvector similarity search<br/>embedding <=> query"| T_JOBS
    T_JOBS -->|"13. Top-200 candidates"| PGVECTOR
    
    PGVECTOR --> NEUMF
    NEUMF -->|"14a. Re-rank (if user in training)"| BANDIT_STUB
    NEUMF -.->|"14b. Cold-start"| COLDSTART
    COLDSTART -.-> BANDIT_STUB
    
    BANDIT_STUB -->|"15. Final ranked items"| RECS_API
    RECS_API -->|"16. Return items"| BE_SERVICE
    
    %% Post-processing
    BE_SERVICE -->|"17. Join career metadata"| T_CAREERS
    BE_SERVICE -->|"18. Filter by RIASEC L1/L2"| BE_SERVICE
    BE_SERVICE -->|"19. Save recommendations"| T_RECS
    BE_SERVICE -->|"20. Return to FE"| UI_RESULTS

    %% Styling
    classDef frontend fill:#e1f5fe,stroke:#01579b
    classDef backend fill:#fff3e0,stroke:#e65100
    classDef aicore fill:#f3e5f5,stroke:#7b1fa2
    classDef database fill:#e8f5e9,stroke:#2e7d32
    classDef model fill:#fce4ec,stroke:#c2185b
    
    class UI_INPUT,UI_RESULTS frontend
    class BE_ASSESS,BE_REC,BE_SERVICE backend
    class TRAITS_API,ESSAY_INFER,RECS_API,LOADER,PGVECTOR,NEUMF,COLDSTART,BANDIT_STUB aicore
    class RIASEC_MODEL,BIG5_MODEL,SBERT model
    class T_ASSESS,T_ESSAYS,T_CAREERS,T_RECS,T_EMB,T_TRAITS,T_JOBS database
```

## So s√°nh v·ªõi s∆° ƒë·ªì g·ªëc

| Th√†nh ph·∫ßn | S∆° ƒë·ªì g·ªëc | Th·ª±c t·∫ø (Code) |
|------------|-----------|----------------|
| **Retrieval** | FAISS Index | ‚ùå **pgvector** (PostgreSQL extension) |
| **Job Embeddings** | FAISS pre-loaded | ‚úÖ `ai.retrieval_jobs_visbert` table |
| **User Embedding** | vi-SBERT | ‚úÖ `vi_sbert_768/` model |
| **NLP Encoder** | PhoBERT | ‚úÖ `riasec_phobert/`, `big5_phobert/` |
| **Ranking** | NeuMF | ‚úÖ `recsys_mlp/best.pt` |
| **Thompson Sampling** | Beta-Bernoulli | ‚ö†Ô∏è **STUB** - ch·ªâ sort by rank_score |
| **Neo4j Graph DB** | Skill roadmap | ‚ùå **Kh√¥ng th·∫•y trong flow ch√≠nh** |
| **Feedback Logs** | Click/Like tracking | ‚ö†Ô∏è C√≥ routes nh∆∞ng kh√¥ng trong main flow |

## Chi ti·∫øt c√°c b∆∞·ªõc

### B∆∞·ªõc 1-8: User l√†m test + AI Scoring

```
User ‚Üí AssessmentPage.tsx
     ‚Üí POST /api/assessments/submit (RIASEC/Big5 test)
     ‚Üí POST /api/assessments/essay
     ‚Üí Backend g·ªçi AI-Core: POST /ai/infer_user_traits
     ‚Üí PhoBERT models predict: riasec[6], big5[5], embedding[768]
     ‚Üí L∆∞u v√†o ai.user_embeddings, ai.user_trait_preds
```

### B∆∞·ªõc 9-16: Retrieval + Ranking

```
User ‚Üí GET /api/recommendations?assessment_id=xxx
     ‚Üí Backend g·ªçi AI-Core: POST /recs/top_careers
     ‚Üí Load embedding t·ª´ ai.user_embeddings
     ‚Üí pgvector search: embedding <=> query ‚Üí Top-200 candidates
     ‚Üí NeuMF re-rank (ho·∫∑c cold-start fallback)
     ‚Üí Bandit stub (ch·ªâ sort)
     ‚Üí Return ranked items
```

### B∆∞·ªõc 17-20: Post-processing

```
Backend:
     ‚Üí Join v·ªõi core.careers ƒë·ªÉ l·∫•y metadata
     ‚Üí Filter theo RIASEC L1/L2 c·ªßa user
     ‚Üí L∆∞u v√†o core.career_recommendations
     ‚Üí Return to Frontend
```

## L∆∞u √Ω quan tr·ªçng

1. **FAISS kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong production retrieval**
   - File `build_mini_index.py` ch·ªâ d√πng cho offline index building
   - Production d√πng pgvector v·ªõi SQL query tr·ª±c ti·∫øp

2. **Thompson Sampling/Bandit l√† STUB**
   - Hi·ªán t·∫°i `recommend_with_bandit()` ch·ªâ sort theo `rank_score`
   - Ch∆∞a implement exploration/exploitation th·ª±c s·ª±

3. **Cold-start handling**
   - Khi user_id kh√¥ng c√≥ trong NeuMF training data
   - Fallback: d√πng retrieval similarity scores l√†m final scores

4. **Neo4j kh√¥ng trong main flow**
   - C√≥ module `modules/graph/neo4j_client.py` nh∆∞ng kh√¥ng ƒë∆∞·ª£c g·ªçi trong recommendation flow ch√≠nh


---

## S∆° ƒë·ªì ƒë∆°n gi·∫£n (Style gi·ªëng s∆° ƒë·ªì g·ªëc)

```mermaid
flowchart LR
    subgraph INPUT["User Input"]
        ESSAY["Essay Text"]
        TEST["RIASEC/Big5 Test"]
    end

    subgraph NLP["NLP Encoder (PhoBERT)"]
        RIASEC_PRED["RIASEC Predictor<br/>‚Üí 6 scores"]
        BIG5_PRED["Big5 Predictor<br/>‚Üí 5 scores"]
        SBERT_ENC["vi-SBERT Encoder<br/>‚Üí 768D embedding"]
    end

    subgraph PROFILE["User Profile"]
        TRAITS["RIASEC + Big5 Scores<br/>(11D vector)"]
        EMB["Essay Embedding<br/>(768D vector)"]
    end

    subgraph RETRIEVAL["Semantic Retrieval"]
        PGVECTOR["pgvector<br/>(PostgreSQL)"]
        JOBS_EMB["Job Embeddings<br/>ai.retrieval_jobs_visbert"]
    end

    subgraph RANKING["Ranking Layer"]
        NEUMF["NeuMF/MLP<br/>recsys_mlp/best.pt"]
        COLDSTART["Cold-start<br/>Fallback"]
    end

    subgraph BANDIT["Bandit (STUB)"]
        THOMPSON["Thompson Sampling<br/>(ch∆∞a implement)"]
    end

    subgraph OUTPUT["Final Output"]
        TOPK["Top-K Careers"]
        FILTER["RIASEC L1/L2 Filter"]
    end

    %% Connections
    ESSAY --> RIASEC_PRED
    ESSAY --> BIG5_PRED
    ESSAY --> SBERT_ENC
    TEST --> TRAITS

    RIASEC_PRED --> TRAITS
    BIG5_PRED --> TRAITS
    SBERT_ENC --> EMB

    EMB -->|"Query vector"| PGVECTOR
    JOBS_EMB -->|"Pre-computed"| PGVECTOR
    PGVECTOR -->|"Top-200 candidates"| NEUMF

    TRAITS -->|"User features"| NEUMF
    NEUMF -->|"Ranked items"| THOMPSON
    NEUMF -.->|"No user in training"| COLDSTART
    COLDSTART -.-> THOMPSON

    THOMPSON --> TOPK
    TRAITS -->|"L1/L2 codes"| FILTER
    TOPK --> FILTER
```

## Sequence Diagram (Chi ti·∫øt)

```mermaid
sequenceDiagram
    autonumber
    participant U as User
    participant FE as Frontend
    participant BE as Backend :8000
    participant AI as AI-Core :9000
    participant DB as PostgreSQL

    rect rgb(230, 245, 255)
        Note over U,DB: Phase 1: User l√†m b√†i test
        U->>FE: L√†m test RIASEC/Big5
        FE->>BE: POST /api/assessments/submit
        BE->>DB: INSERT core.assessments
        BE-->>FE: assessment_id
    end

    rect rgb(255, 243, 224)
        Note over U,DB: Phase 2: User submit Essay
        U->>FE: Vi·∫øt essay
        FE->>BE: POST /api/assessments/essay
        BE->>DB: INSERT core.essays
        
        BE->>AI: POST /ai/infer_user_traits
        Note right of AI: PhoBERT RIASEC<br/>PhoBERT Big5<br/>vi-SBERT embedding
        AI-->>BE: {riasec[], big5[], embedding[768]}
        
        BE->>DB: UPSERT ai.user_embeddings
        BE->>DB: UPSERT ai.user_trait_preds
        BE-->>FE: essay_id, traits
    end

    rect rgb(243, 229, 245)
        Note over U,DB: Phase 3: Get Recommendations
        U->>FE: Xem k·∫øt qu·∫£
        FE->>BE: GET /api/recommendations?assessment_id=xxx
        
        BE->>AI: POST /recs/top_careers
        
        AI->>DB: SELECT emb FROM ai.user_embeddings
        DB-->>AI: embedding[768]
        
        AI->>DB: SELECT job_id, score<br/>FROM ai.retrieval_jobs_visbert<br/>ORDER BY embedding <-> query
        DB-->>AI: candidates[200]
        
        Note right of AI: NeuMF re-rank<br/>(or cold-start fallback)
        AI-->>BE: ranked_items[]
    end

    rect rgb(232, 245, 233)
        Note over U,DB: Phase 4: Post-processing
        BE->>DB: SELECT FROM core.careers
        DB-->>BE: career metadata
        
        Note right of BE: Filter by RIASEC L1/L2
        
        BE->>DB: INSERT core.career_recommendations
        BE-->>FE: {items: [...]}
        FE-->>U: Hi·ªÉn th·ªã k·∫øt qu·∫£
    end
```

## B·∫£ng so s√°nh chi ti·∫øt

| Component | S∆° ƒë·ªì g·ªëc | Code th·ª±c t·∫ø | File location |
|-----------|-----------|--------------|---------------|
| **Retrieval Engine** | FAISS | pgvector | `service_pgvector.py` |
| **Retrieval Table** | FAISS Index | `ai.retrieval_jobs_visbert` | PostgreSQL |
| **Similarity Metric** | Cosine (FAISS) | `<=>` operator (pgvector) | SQL query |
| **RIASEC Model** | PhoBERT | ‚úÖ PhoBERT | `models/riasec_phobert/` |
| **Big5 Model** | PhoBERT | ‚úÖ PhoBERT | `models/big5_phobert/` |
| **Embedding Model** | vi-SBERT | ‚úÖ vi-SBERT | `models/vi_sbert_768/` |
| **Ranking Model** | NeuMF | ‚úÖ MLP | `models/recsys_mlp/` |
| **Bandit** | Thompson Sampling | ‚ö†Ô∏è STUB | `bandit.py` |
| **Neo4j** | Skill roadmap | ‚ùå Not in main flow | `neo4j_client.py` |
| **Feedback Loop** | Click/Like ‚Üí Bandit | ‚ö†Ô∏è Routes exist | `routes_tracking.py` |

## K·∫øt lu·∫≠n

S∆° ƒë·ªì g·ªëc c√≥ m·ªôt s·ªë ƒëi·ªÉm **kh√¥ng ch√≠nh x√°c** so v·ªõi code th·ª±c t·∫ø:

1. ‚ùå **FAISS** ‚Üí Th·ª±c t·∫ø d√πng **pgvector**
2. ‚ö†Ô∏è **Thompson Sampling** ‚Üí Ch·ªâ l√† **stub**, ch∆∞a implement
3. ‚ùå **Neo4j Graph DB** ‚Üí Kh√¥ng trong main recommendation flow
4. ‚ö†Ô∏è **Feedback Loop** ‚Üí Routes t·ªìn t·∫°i nh∆∞ng kh√¥ng k·∫øt n·ªëi v·ªõi bandit

C√°c th√†nh ph·∫ßn **ch√≠nh x√°c**:
- ‚úÖ PhoBERT cho RIASEC/Big5 prediction
- ‚úÖ vi-SBERT cho essay embedding
- ‚úÖ NeuMF/MLP cho ranking
- ‚úÖ RIASEC L1/L2 filtering
