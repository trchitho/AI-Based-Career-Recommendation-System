backbone_tokenizer_dir: models/riasec_phobert
max_length: 256
splits:
  - name: train
    input: data/processed/train.jsonl
    text_field_candidates: [text, essay_text, essay, content]
    output_npy: data/embeddings/train_embeddings.npy
  - name: val
    input: data/processed/val.jsonl
    text_field_candidates: [text, essay_text, essay, content]
    output_npy: data/embeddings/val_embeddings.npy
  - name: test
    input: data/processed/test.jsonl
    text_field_candidates: [text, essay_text, essay, content]
    output_npy: data/embeddings/test_embeddings.npy
index_json: data/embeddings/index.json
